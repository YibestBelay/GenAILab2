{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed5bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de681454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = BertModel.from_pretrained(\n",
    "    model_name,\n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The mechanic inspected the engine because it was noisy.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc10829",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b057c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "attentions = outputs.attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57724e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "head = 0\n",
    "\n",
    "attention_matrix = attentions[layer][0, head].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd865b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(attention_matrix, cmap=\"viridis\")\n",
    "\n",
    "plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "plt.yticks(range(len(tokens)), tokens)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.title(\"Self-Attention Heatmap (Layer 1, Head 0)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"outputs/attention_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893e39d",
   "metadata": {},
   "source": [
    "A2 â€” Understand Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e6c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_original = \"The cat sat on the mat\"\n",
    "sentence_scrambled = \"Mat the on sat cat the\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb70e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Last hidden state: (batch, seq_len, hidden_dim)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Mean pooling over tokens\n",
    "    sentence_embedding = token_embeddings.mean(dim=1)\n",
    "\n",
    "    return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201735b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_original = get_sentence_embedding(sentence_original)\n",
    "emb_scrambled = get_sentence_embedding(sentence_scrambled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7efc8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7193946838378906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_similarity = F.cosine_similarity(\n",
    "    emb_original, emb_scrambled\n",
    ")\n",
    "\n",
    "sentence_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f6d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embeddings(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    return outputs.last_hidden_state.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829648da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7193946838378906"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_original = get_token_embeddings(sentence_original)\n",
    "tokens_scrambled = get_token_embeddings(sentence_scrambled)\n",
    "\n",
    "token_level_similarity = F.cosine_similarity(\n",
    "    tokens_original.mean(dim=0),\n",
    "    tokens_scrambled.mean(dim=0),\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "token_level_similarity.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
